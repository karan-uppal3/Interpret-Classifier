{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision_tree.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dccCQfKgPniP",
        "OFXbeSPpY2Xy",
        "YD2YSIvCIcbQ",
        "DflCPPlc_NXe"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr523Yq5OBbB"
      },
      "source": [
        "model_path = \"/content/drive/MyDrive/Interpretable Classifier Data/SemSeg Model/best_model.pt\"\r\n",
        "data_path = \"/content/drive/MyDrive/Interpretable Classifier Data/Decision Tree Data\"\r\n",
        "save_path = \"/content/drive/MyDrive/Interpretable Classifier Data/Decision Tree Model\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPfblQNKSndg"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE0r00YZSpXS"
      },
      "source": [
        "import torch\r\n",
        "from torchvision import transforms\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import torch.nn.functional as F\r\n",
        "import os\r\n",
        "import cv2\r\n",
        "import csv  \r\n",
        "import graphviz\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "from joblib import dump\r\n",
        "from model import ENet\r\n",
        "from utils import load_ckp, decode_segmap, counter\r\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dccCQfKgPniP"
      },
      "source": [
        "# Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haKP4dvhNiiC"
      },
      "source": [
        "model = ENet(num_classes=3).to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rweJVsbxQReK"
      },
      "source": [
        "# define optimzer\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=5e-4,weight_decay=2e-4)\n",
        "\n",
        "# define checkpoint saved path\n",
        "ckp_path = model_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvIoLs_8Qj_a"
      },
      "source": [
        "model, optimizer, start_epoch, valid_loss_min = load_ckp(ckp_path, model, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6TFlL14QmCA"
      },
      "source": [
        "print(\"start_epoch = \", start_epoch)\n",
        "print(\"valid_loss_min = \", valid_loss_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFXbeSPpY2Xy"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBRTieNxZDZ_"
      },
      "source": [
        "# Tranformation for the input images \n",
        "transform_img = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erCCE5ceZDaA"
      },
      "source": [
        "class dataset(Dataset):\r\n",
        "  \"\"\"Custom Dataset class for ease of operation\"\"\"\r\n",
        "\r\n",
        "  def __init__(self, images_X, images_Y, transform_img):\r\n",
        "    self.data=images_X\r\n",
        "    self.labels=images_Y\r\n",
        "    self.transform=transform_img\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.data)\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    x = self.data[index]\r\n",
        "    y = self.labels[index]\r\n",
        "    x = self.transform(x)\r\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ0sLXuTY7VK"
      },
      "source": [
        "image_list_X_test = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ptsjYRDY7VM"
      },
      "source": [
        "num_bicycles = len(os.listdir(data_path+'/bicycle/'))\n",
        "\n",
        "for imagename in sorted(os.listdir(data_path+'/bicycle/')): \n",
        "  im=cv2.imread(data_path+'/bicycle/'+imagename)\n",
        "  image_list_X_test.append(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFH29tXwY7VN"
      },
      "source": [
        "num_unicycles = len(os.listdir(data_path+'/unicycle/'))\n",
        "\n",
        "for imagename in sorted(os.listdir(data_path+'/unicycle/')): \n",
        "  im=cv2.imread(data_path+'/unicycle/'+imagename)\n",
        "  image_list_X_test.append(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzPFsSgrY7VN"
      },
      "source": [
        "num_negative = len(os.listdir(data_path+'/negative/'))\n",
        "\n",
        "for imagename in sorted(os.listdir(data_path+'/negative/')): \n",
        "  im=cv2.imread(data_path+'/negative/'+imagename)\n",
        "  image_list_X_test.append(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYOmvmRMY7VO"
      },
      "source": [
        "images_X_test = np.array(image_list_X_test)\r\n",
        "y = [2]*num_bicycles + [1]*num_unicycles + [0]*num_negative"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQSBmm5kY7VP"
      },
      "source": [
        "test_data = dataset(images_X=images_X_test, images_Y=y, transform_img=transform_img)\n",
        "test_loader = DataLoader(test_data, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD2YSIvCIcbQ"
      },
      "source": [
        "# Creating CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu-rGUr2hWbD"
      },
      "source": [
        "# data rows of csv file  \n",
        "rows = []  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAfsxRwSJcOO"
      },
      "source": [
        "# field names  \n",
        "fields = ['Num_Wheels', 'Num_Frames', 'Label']  \n",
        "       \n",
        "# name of csv file  \n",
        "filename = \"data.csv\"\n",
        "\n",
        "for img, label in test_loader:\n",
        "\n",
        "  model.eval()\n",
        "  \n",
        "  xb = img.to('cuda')\n",
        "\n",
        "  yb = model(xb)\n",
        "\n",
        "  pred = F.softmax(yb, dim=1)                   \n",
        "  preds = torch.argmax(pred, dim=1).squeeze(1)\n",
        "\n",
        "  preds = preds.cpu()\n",
        "\n",
        "  x = decode_segmap(preds,nc=3)\n",
        "  x = x.squeeze(0)\n",
        "\n",
        "  temp = counter(x)\n",
        "  temp.append(int(label))\n",
        "  rows.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxIQrK_bamN3"
      },
      "source": [
        "# writing to csv file  \r\n",
        "with open(filename, 'w') as csvfile:  \r\n",
        "    # creating a csv writer object  \r\n",
        "    csvwriter = csv.writer(csvfile)  \r\n",
        "        \r\n",
        "    # writing the fields  \r\n",
        "    csvwriter.writerow(fields)  \r\n",
        "        \r\n",
        "    # writing the data rows  \r\n",
        "    csvwriter.writerows(rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DflCPPlc_NXe"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmIABgep_Qnm"
      },
      "source": [
        "data = pd.read_csv('data.csv')\n",
        "y = data['Label']\n",
        "data = data.drop(['Label'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3ZTSldm_4H1"
      },
      "source": [
        "classifier = DecisionTreeClassifier(max_leaf_nodes=5, max_depth=4)\n",
        "clf = classifier.fit(data,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-unJAn6sAV4z"
      },
      "source": [
        "dot_data = export_graphviz(classifier, out_file=None,\n",
        "                           feature_names=data.columns,  \n",
        "                     class_names=['neither','unicycle','bicycle'],precision=1,rounded=True,filled=True) \n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJpOjdUwIQAd"
      },
      "source": [
        "print(confusion_matrix(y, clf.predict(data)))\r\n",
        "print(classification_report(y, clf.predict(data)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aQ0cvxFYHQB"
      },
      "source": [
        "cf = confusion_matrix(y, clf.predict(data))\r\n",
        "sns.heatmap(cf, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VLIrE41fuJS"
      },
      "source": [
        "# saving decision tree classifier\r\n",
        "dump(clf, save_path + '/tree.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
