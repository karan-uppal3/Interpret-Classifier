{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemSeg_train",
      "provenance": [],
      "collapsed_sections": [
        "Y2b6_Uanu_UA",
        "rx46Oe5UIL2U",
        "E_8V2UWxLHCy",
        "dccCQfKgPniP",
        "5Oxg6E0hNmcL",
        "2iksgAaec--b"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCUt7J-TAkTV"
      },
      "source": [
        "val_size_ratio = 0.18\r\n",
        "batch_size = 10\r\n",
        "num_epochs = 300\r\n",
        "lr = 5e-4\r\n",
        "weight_decay = 2e-4\r\n",
        "checkpoint_path = \"./checkpoint/current_checkpoint.pt\"\r\n",
        "best_model_path = \"./best_model/best_model.pt\"\r\n",
        "path_to_data = \"/content/drive/MyDrive/Interpretable Classifier Data/SemSeg Data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DaF3RIE_3fK"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3MMPREW_8Tx"
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from model import ENet\n",
        "from utils import decode_segmap, to_device, IOU, save_ckp, load_ckp\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2b6_Uanu_UA"
      },
      "source": [
        "# Loading data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXegnlGP1QCo"
      },
      "source": [
        "# Tranformation for the input images \n",
        "transform_img = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XBYu3V4B0BT"
      },
      "source": [
        "class dataset(Dataset):\r\n",
        "  \"\"\"Custom Dataset class for ease of operation\"\"\"\r\n",
        "\r\n",
        "  def __init__(self, images_X, images_Y, transform_img):\r\n",
        "    self.data=images_X\r\n",
        "    self.labels=images_Y\r\n",
        "    self.transform=transform_img\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.data)\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    x = self.data[index]\r\n",
        "    y = self.labels[index]\r\n",
        "    x = self.transform(x)\r\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jaff95WEuuTe"
      },
      "source": [
        "image_list_X = []\n",
        "\n",
        "for imagename in sorted(os.listdir(path_to_data+'/images/')) : \n",
        "  im=cv2.imread(path_to_data+'/images/'+imagename)\n",
        "  image_list_X.append(im)\n",
        "\n",
        "images_X = np.array(image_list_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f70BsL_s0xMF"
      },
      "source": [
        "image_list_Y = []\n",
        "\n",
        "for imagename in sorted(os.listdir(path_to_data+'/labels/')): \n",
        "  im=cv2.imread(path_to_data+'/labels/'+imagename,0)\n",
        "  image_list_Y.append(im)\n",
        "\n",
        "images_Y = np.array(image_list_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP6bhkYwCH5t"
      },
      "source": [
        "images_X_train, images_X_val, images_Y_train, images_Y_val = train_test_split( images_X, images_Y, test_size = val_size_ratio , shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM2umcfX1Iqm"
      },
      "source": [
        "train_data = dataset( images_X = images_X_train, images_Y = images_Y_train, transform_img = transform_img )\n",
        "train_loader = DataLoader( train_data, batch_size = batch_size )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhDRX39zWbmg"
      },
      "source": [
        "val_data = dataset( images_X = images_X_val, images_Y = images_Y_val, transform_img = transform_img )\n",
        "val_loader = DataLoader( val_data, batch_size = 1 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx46Oe5UIL2U"
      },
      "source": [
        "# Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z99ca8omOUsq"
      },
      "source": [
        "%mkdir checkpoint best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJbpnh4FIW6p"
      },
      "source": [
        "def evaluate(model,val_loader,epoch,criterion):\n",
        "  \"\"\"To evaluate the validation set after each epoch\"\"\"\n",
        "\n",
        "  acc = 0\n",
        "  epoch_loss = 0.0\n",
        "  a = np.zeros((3,), dtype=float)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  for img,label in val_loader:\n",
        "\n",
        "    model.eval()\n",
        "  \n",
        "    xb = img.to('cuda')\n",
        "    label = label.to('cuda').long()\n",
        "\n",
        "    yb = model(xb)\n",
        "\n",
        "    loss = criterion(yb, label)\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    pred = F.softmax(yb, dim=1)\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "\n",
        "    preds = preds.cpu()\n",
        "    label = label.cpu()\n",
        "\n",
        "    temp = (np.array( preds == label )).sum() / ( 256*512 )\n",
        "    acc += temp\n",
        "    a += IOU(np.array(preds[0]),np.array(label[0]))\n",
        "\n",
        "  print(\"Accuracy = \",acc*100/len(val_loader))\n",
        "  print(\"------------\")\n",
        "\n",
        "  return {\"Class IOU\":a*100/len(val_loader),\"Mean IOU\":(a*100/len(val_loader)).mean(),\"Accuracy\":acc*100/len(val_loader),\"Loss\":epoch_loss/len(val_loader)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS3W078LRKbf"
      },
      "source": [
        "def fit(epochs, lr, model, train_loader, val_loader,criterion,opt_func=torch.optim.Adam,checkpoint_path=\"/content/checkpoint/current_checkpoint.pt\", best_model_path=\"/content/best_model/best_model.pt\"):\n",
        "\n",
        "    epoch_data = {}\n",
        "    optim = opt_func( model.parameters(), lr = lr, weight_decay = weight_decay )\n",
        "\n",
        "    valid_loss_min = np.Inf\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      \n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for step, batch_data in enumerate(train_loader):\n",
        "\n",
        "            # Get the inputs and labels\n",
        "            inputs = batch_data[0].to('cuda')\n",
        "            labels = batch_data[1].to('cuda').long()\n",
        "\n",
        "            # Forward propagation\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Loss computation\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backpropagation\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            # Keep track of loss for current epoch\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        epoch_data[epoch+1] = evaluate(model,val_loader,epoch+1,criterion)\n",
        "        val_loss = epoch_data[epoch+1][\"Loss\"]\n",
        "\n",
        "        print(\"Epoch number:\",epoch+1,\" - Training Loss = \" , epoch_loss / len(train_loader) , \" Valiadtion Loss = \", val_loss )\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'valid_loss_min': valid_loss_min,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optim.state_dict(),\n",
        "        }\n",
        "\n",
        "        save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
        "\n",
        "        if val_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,val_loss))\n",
        "            # save checkpoint as best model\n",
        "            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "            valid_loss_min = val_loss\n",
        "\n",
        "        print(\"------------\")\n",
        "\n",
        "    return epoch_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_8V2UWxLHCy"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txZda0t4LNqJ"
      },
      "source": [
        "model = ENet(num_classes=3).to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urJZQ8XAh5JM"
      },
      "source": [
        "def get_class_weights(loader, num_classes, c=1.02):\n",
        "\n",
        "    _, y= next(iter(loader))\n",
        "    y_flat = y.flatten()\n",
        "\n",
        "    each_class = np.bincount(y_flat, minlength=num_classes)\n",
        "    p_class = each_class / len(y_flat)\n",
        "    class_weights = 1 / (np.log(c + p_class))\n",
        "\n",
        "    return class_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cy64V77LQvZ"
      },
      "source": [
        "# Class weights are assigned on the basis of their occurence in an image\n",
        "# Suppose a particular label is present in most of the image, it will have\n",
        "# a lower weight, hence contributing less towards back propagation\n",
        "class_weights = get_class_weights(train_loader, 3)\n",
        "class_weights = torch.from_numpy(class_weights).float().to('cuda')\n",
        "criterion = nn.CrossEntropyLoss( weight = class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quZunoFILVlB"
      },
      "source": [
        "epoch_data = fit(num_epochs, lr, model, train_loader, val_loader , criterion, checkpoint_path=checkpoint_path, best_model_path=best_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dccCQfKgPniP"
      },
      "source": [
        "# Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haKP4dvhNiiC"
      },
      "source": [
        "model = ENet(num_classes=3).to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rweJVsbxQReK"
      },
      "source": [
        "# define optimzer\n",
        "optimizer = torch.optim.Adam( model.parameters(), lr = lr, weight_decay = weight_decay )\n",
        "\n",
        "# define checkpoint saved path\n",
        "ckp_path = best_model_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvIoLs_8Qj_a"
      },
      "source": [
        "model, optimizer, start_epoch, valid_loss_min = load_ckp(ckp_path, model, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6TFlL14QmCA"
      },
      "source": [
        "print(\"start_epoch = \", start_epoch)\n",
        "print(\"valid_loss_min = \", valid_loss_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Oxg6E0hNmcL"
      },
      "source": [
        "# Train again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q94QkJ1hi1Zo"
      },
      "source": [
        "def train_again(start_epoch,epochs,valid_loss_min,model,optim,train_loader,val_loader,criterion,checkpoint_path=\"./checkpoint/current_checkpoint.pt\", best_model_path=\"./best_model/best_model.pt\"):\n",
        "\n",
        "    epoch_data = {}\n",
        "\n",
        "    for epoch in range(start_epoch,epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for step, batch_data in enumerate(train_loader):\n",
        "\n",
        "            # Get the inputs and labels\n",
        "            inputs = batch_data[0].to('cuda')\n",
        "            labels = batch_data[1].to('cuda').long()\n",
        "\n",
        "            # Forward propagation\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Loss computation\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backpropagation\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            # Keep track of loss for current epoch\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        epoch_data[epoch+1] = evaluate(model,val_loader,epoch+1,criterion)\n",
        "        val_loss = epoch_data[epoch+1][\"Loss\"]\n",
        "\n",
        "        print(\"Epoch number:\",epoch+1,\" - Training Loss = \" , epoch_loss / len(train_loader) , \" Valiadtion Loss = \", val_loss )\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'valid_loss_min': val_loss,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optim.state_dict(),\n",
        "        }\n",
        "\n",
        "        save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
        "\n",
        "        if val_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,val_loss))\n",
        "            # save checkpoint as best model\n",
        "            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "            valid_loss_min = val_loss\n",
        "\n",
        "        print(\"------------\")\n",
        "\n",
        "    return epoch_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "319U5B9_jhFv"
      },
      "source": [
        "epoch_data = train_again(start_epoch, epochs, valid_loss_min, model, optimizer, train_loader, val_loader, criterion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iksgAaec--b"
      },
      "source": [
        "# Evauating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SPO7JtVWRDrI"
      },
      "source": [
        "acc = 0\n",
        "epoch_loss = 0.0\n",
        "a = np.zeros((3,), dtype=float)\n",
        "k = 0\n",
        "\n",
        "for img,label in val_loader:\n",
        "\n",
        "  model.eval()\n",
        "  \n",
        "  xb = img.to('cuda')\n",
        "  label = label.to('cuda').long()\n",
        "\n",
        "  yb = model(xb)\n",
        "\n",
        "  pred = F.softmax(yb, dim=1)             \n",
        "  preds = torch.argmax(pred, dim=1).squeeze(1)\n",
        "\n",
        "  preds = preds.cpu()\n",
        "  label = label.cpu()\n",
        "\n",
        "  temp = (np.array( preds == label )).sum() / ( 256*512 )\n",
        "  acc += temp\n",
        "\n",
        "  a += IOU(np.array(preds[0]),np.array(label[0]))\n",
        "\n",
        "  row, col = 1, 3\n",
        "  fig, axs = plt.subplots(row, col, figsize=(21, 10))\n",
        "  fig.tight_layout()\n",
        "\n",
        "  axs[0].imshow(cv2.cvtColor(images_X_val[k], cv2.COLOR_BGR2RGB))\n",
        "  axs[0].set_title('Original')\n",
        "\n",
        "  x = decode_segmap(preds,nc=3)\n",
        "  x = x.squeeze(0)\n",
        "\n",
        "  axs[1].imshow(cv2.cvtColor(x, cv2.COLOR_BGR2RGB))\n",
        "  axs[1].set_title('Output')\n",
        "\n",
        "  idx = x == 0\n",
        "  x[idx] = images_X_val[k][idx]\n",
        "\n",
        "  added_image = cv2.addWeighted(images_X_val[k],0.2,x,0.9,0)\n",
        "\n",
        "  axs[2].imshow(cv2.cvtColor(added_image, cv2.COLOR_BGR2RGB))\n",
        "  axs[2].set_title('Overlay')\n",
        "\n",
        "  k = k + 1\n",
        "\n",
        "print(\"Class IoU\",(a/len(val_loader)).mean(),\"Accuracy\",acc/len(val_loader))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
